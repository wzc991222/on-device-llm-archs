{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e86ad4f-aad1-4353-965b-88c4776b2db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from einops import rearrange, repeat\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "c92e9953-470d-4230-a776-c0aeb3443181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048576000"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8 * 8 * 2048 * 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a2b8a42-64f7-4dc6-b948-22a5dd0d4a37",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangzongcheng/.pyenv/versions/3.11.0/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f34f793-bdb8-4fcd-941a-7e89340791d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5e879ba-f5f8-4489-80bb-af1a5b69fa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "81a5c90c-a70d-4a13-81bf-96a7a85a6749",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  340,   345,   517,  1909,  1165,   783,   502,   994,   640,\n",
       "          503],\n",
       "       [  198, 50256,    20,    19,    17,    23,    82,   362,   278,\n",
       "          352],\n",
       "       [  198,   327, 15886, 50256,    91,  6494,   250,   376,  4522,\n",
       "          685],\n",
       "       [15886,   198,  1294,  2937,    91,   327,   311,   317, 50256,\n",
       "        31440],\n",
       "       [ 1802,  2026,   838,  1160,    20,  1542,   642,  4019,  1679,\n",
       "         4101],\n",
       "       [  371,   311,  5161,   317,  1195,   347,   337,   360,   367,\n",
       "          350],\n",
       "       [  198,   440,   259,   288,   267,   364,   300,   360,    82,\n",
       "          642],\n",
       "       [  198, 50256, 15886, 24555, 22219,   250,    17,    16,    91,\n",
       "           20],\n",
       "       [   16,    17,    82,    18,    64,   251,    19,    65,    20,\n",
       "           32],\n",
       "       [  198, 50256, 15886,     0, 11146,   427,   277,    91,    11,\n",
       "        25998],\n",
       "       [  198,   830,  3012,    17, 15886,   317,  1160,  1802,  2026,\n",
       "          838],\n",
       "       [  340,  2102,   640,    82,   326,   614,   531,   812,   352,\n",
       "          345],\n",
       "       [  198,  1729,  2116,  1462,  1029,   880,   890,   763,  1941,\n",
       "          662],\n",
       "       [  340,   531,    50,   471,   640,   606,   345,    16,   614,\n",
       "          502],\n",
       "       [  785,   290,   352,    16,  2398,   513,  1987,   860,   266,\n",
       "           18],\n",
       "       [   13,    12,   357, 15886,   720,   198,    28,    11,    14,\n",
       "          532],\n",
       "       [  198,    13,    12,   720,   357,  1303,    25, 15886,     7,\n",
       "           14],\n",
       "       [  198,    13,    12,    14,   357,   720,     7, 15886,  1303,\n",
       "         7375],\n",
       "       [  198,    13,    12,   357,   720,    14, 15886,     7,  4904,\n",
       "         1303],\n",
       "       [  198,    13,    12,    14,   357,   720, 15886,     7,    25,\n",
       "         1303],\n",
       "       [   13,   198,    12,   720,   357,    14, 15886,    11,    25,\n",
       "            7],\n",
       "       [   13,   198,    12,   357,   720,    14, 15886,    25,    11,\n",
       "            7],\n",
       "       [   13,   198,    12,    14,   357,   720,    11, 15886,    25,\n",
       "            7],\n",
       "       [   13,    12,   198,    14,   357,   720,    11, 15886,    25,\n",
       "          569],\n",
       "       [   13,    12,   198,   357,   720,    11,    25,    14, 15886,\n",
       "         1906],\n",
       "       [  352,   362,   531,   513,   838,   604,   642,   767,   718,\n",
       "         1367],\n",
       "       [  340,   251,   606,    82,   345,   640, 20766,   502,   683,\n",
       "         2624],\n",
       "       [  198,    79,   279,    47,   350,    91, 15886, 50256,    28,\n",
       "           25],\n",
       "       [  312,    85,  6371,    77,    79,   198,  2389,   279,  4686,\n",
       "         5420],\n",
       "       [  198,   785,    79,    64,  2398,  1671,   784,    13,   366,\n",
       "           65],\n",
       "       [  340,   345,   826,   326,   428,   466,   502,   606,   329,\n",
       "          783],\n",
       "       [ 3672,  3053,   198, 12888,  7508,   250,    13, 50256,     7,\n",
       "          986],\n",
       "       [  198, 50256,    13,    12,   250,   357,   366,     5,    14,\n",
       "            1],\n",
       "       [  198,   357,    12,    13, 50256,   250,     5,    14,    17,\n",
       "          366],\n",
       "       [  198,    13,   357,    12, 50256,    14,  7200,   250,   366,\n",
       "           91],\n",
       "       [  198,    13,   513,   357,    12, 50256,     5,   250,    14,\n",
       "          366],\n",
       "       [  198,    13,   357,    12, 50256,   250,    14,     5,   366,\n",
       "        15886],\n",
       "       [  198,   357,    12, 50256,    13,   250, 15886,  7200,   366,\n",
       "           14],\n",
       "       [  198,   357,    12, 50256,    13,   250,   642,   604,   513,\n",
       "          366],\n",
       "       [  198,   357,    12, 50256,    13,   250,   366,    14, 15886,\n",
       "         2022],\n",
       "       [  198,   250,   366, 50256,     1,   357,    13,   246,    12,\n",
       "          986],\n",
       "       [  198,    13,   357,    12, 50256,   250,   366,    14,    32,\n",
       "        15886],\n",
       "       [  198,   357,    13,    12, 50256,   604,   250,  3486,   366,\n",
       "          642],\n",
       "       [  198,   357,    12,    13, 50256,   250,    14,   366, 15886,\n",
       "           91],\n",
       "       [  198,   357,    12,    13, 50256,   250,     5,  8740,    14,\n",
       "          366],\n",
       "       [  198,   357,    12,    13, 50256,   250, 15886,    14,   366,\n",
       "           91],\n",
       "       [  198,    13,    12,   357,    14,   250, 50256,    17,   366,\n",
       "           56],\n",
       "       [  198,   357,    12,    13, 50256,   250,     5,   366,    14,\n",
       "        13793],\n",
       "       [  198,   357,    12, 50256,    13,   327,   337,    14,   402,\n",
       "           32],\n",
       "       [  198,   357,    13,    12, 50256,   250,    14,   366, 15886,\n",
       "            5],\n",
       "       [   13,   198,   357,    12, 50256,     6,   250,    14,   247,\n",
       "          366],\n",
       "       [  198,    12,   357,    13,     5, 50256,   250,    14,   366,\n",
       "        15886],\n",
       "       [  198,   357,    12,    13, 50256, 12460,  6579,   399,   250,\n",
       "          509],\n",
       "       [  198,   357,    12,   367,    13, 50256,    14,   250,   370,\n",
       "          366],\n",
       "       [  198,   357,    12,    13, 50256,   250,    14,   366,    91,\n",
       "        15886],\n",
       "       [  198,    12,   357,   327,  2538,    14,    49, 21664,   402,\n",
       "        15886],\n",
       "       [  198,    13,   357,    12, 50256,   250, 20571,  6489, 17931,\n",
       "         2767],\n",
       "       [  198,    12,   357,   412, 50256,   250,  2043,   327,    13,\n",
       "         3537],\n",
       "       [  198,   250, 50256,    91, 15886,   251,  1399,   986,   246,\n",
       "            0],\n",
       "       [25150,    13,    77,   198,    81, 30206, 44171, 13283,    62,\n",
       "        11209],\n",
       "       [ 6861,    82, 11713,  8134,   392,    64,   251, 21383,  2723,\n",
       "         6371],\n",
       "       [  198, 10563,    62,    13,   838,     8,    87,    12,   510,\n",
       "          362],\n",
       "       [   16,   198,    64,  1659, 26841,    17,  1169, 10563,    82,\n",
       "          259],\n",
       "       [  314,   836,   340,   198,   345,   632,   356,   326,  1422,\n",
       "          460],\n",
       "       [  357,    12,   198,   250,   960,     7,   366,    13,  4489,\n",
       "          514],\n",
       "       [   12,   357,   198,     7,    14,    13,   250,   366,   398,\n",
       "          275],\n",
       "       [   12,   357,   198,    14,     7,    13,   250,   319,   366,\n",
       "         1550],\n",
       "       [  247,    12,    17,   198,   357,    14,    18,    13,   250,\n",
       "          513],\n",
       "       [   13,   357,    12,   198,     7,  5899,    14, 16334, 19977,\n",
       "          500],\n",
       "       [   12,   198,   357,   250,    14,    13,   366,  4580,   523,\n",
       "         2270],\n",
       "       [   13,    12,   198,    14,   357,   250,  2537, 46832,   366,\n",
       "          337],\n",
       "       [   12,    14,   198,   357,    13,   250,   397,   283,   366,\n",
       "          732],\n",
       "       [  357,   198,    13,    12, 28931,  4715,  1669, 20493,  1162,\n",
       "            7],\n",
       "       [   14,    12,    13,   198,  8498,   430,  1215,  1526,   357,\n",
       "          440],\n",
       "       [  334,    12,    13,     7,   357,  2471,    14,   198,  1288,\n",
       "         8906],\n",
       "       [   12,   198,    14,   357,    13,   250,   425,  8105,   366,\n",
       "         1526],\n",
       "       [  247,    13,    12,    14,   198,   357, 40601,   250,  3652,\n",
       "         7245],\n",
       "       [   12,   357,   198,    13,    14,   246,   705,  1855,     6,\n",
       "          247],\n",
       "       [  800,   198,    12, 22354,    14, 21631, 10335,  1030,    13,\n",
       "          755],\n",
       "       [   12,   357,   198,    13,    14,   250, 17729,   366, 26250,\n",
       "          337],\n",
       "       [  311,  8678,    65,   314,   317, 19413,  2743,  4653,   412,\n",
       "           12],\n",
       "       [   12,   198,    13,   357,    14,  7956, 11033,   911,   450,\n",
       "          285],\n",
       "       [  247,    12,     7,    14,   246,   198,  7169,  8069,  6303,\n",
       "          357],\n",
       "       [  247,    12,   198,    14,   357,   250,    13,  8836,   366,\n",
       "         1378],\n",
       "       [ 1976, 22249,  6658,   267,  1188,  3059,  1765,   324,   300,\n",
       "         4118],\n",
       "       [   12,   357,   198,    13,    14,   645,    30, 23167,  1540,\n",
       "          250],\n",
       "       [   12,   198,    14,   357,   250,    13,   366,    65,   390,\n",
       "         2046],\n",
       "       [ 1674,  4558,    13,   352,   604,   362, 20934,    12,   502,\n",
       "          513],\n",
       "       [   12,  1304,  3311, 23527,  2344,  8615,   299,  1633,  4534,\n",
       "        12332],\n",
       "       [   12,  9940,  7364,  1360,  6069,   763,   710,  3248,  2501,\n",
       "         4849],\n",
       "       [   78,    94,    46,    70,    54,    38,    86,    22,    50,\n",
       "           26],\n",
       "       [  198,    13, 14726, 50256,     4,   405,     0,  3122,    16,\n",
       "           25],\n",
       "       [  198,  1058,   930,    12,    91,   407,  2314,     0,   286,\n",
       "           25],\n",
       "       [  198,    14,     9,  4907,    25,    13, 15886,     0, 50256,\n",
       "           91],\n",
       "       [  126,   140, 12466, 19567,  1587,  6184,   118,   165,   167,\n",
       "          447],\n",
       "       [ 6184,   147, 19567, 12466,   140,   165, 14360,   251, 17550,\n",
       "          252],\n",
       "       [26292, 19567, 17550,   148,   118,   129, 11976, 12466,   138,\n",
       "          119],\n",
       "       [11976, 43074, 32391, 12520,   126,  8582,  6184, 46695,   106,\n",
       "        24231],\n",
       "       [20724,   129, 41585, 19567,   242, 33768, 20015, 35705,   126,\n",
       "        17550],\n",
       "       [  126, 11976, 20724,   123, 27764,   167, 28225,   165,   147,\n",
       "          224]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9e2a54e-ad91-4d5a-83c5-d6e99996a1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = tokenizer.decode(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dcd90ec9-5564-47e3-9f9c-f9e5336789a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' it you more today too now me here time out'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71115adb-4dee-4f17-87a3-1710da1fbbd1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  340,   345,   517,  1909,  1165,   783,   502,   994,   640,   503],\n",
       "        [  198, 50256,    20,    19,    17,    23,    82,   362,   278,   352],\n",
       "        [  198,   327, 15886, 50256,    91,  6494,   250,   376,  4522,   685],\n",
       "        [15886,   198,  1294,  2937,    91,   327,   311,   317, 50256, 31440],\n",
       "        [ 1802,  2026,   838,  1160,    20,  1542,   642,  4019,  1679,  4101],\n",
       "        [  371,   311,  5161,   317,  1195,   347,   337,   360,   367,   350],\n",
       "        [  198,   440,   259,   288,   267,   364,   300,   360,    82,   642],\n",
       "        [  198, 50256, 15886, 24555, 22219,   250,    17,    16,    91,    20],\n",
       "        [   16,    17,    82,    18,    64,   251,    19,    65,    20,    32],\n",
       "        [  198, 50256, 15886,     0, 11146,   427,   277,    91,    11, 25998],\n",
       "        [  198,   830,  3012,    17, 15886,   317,  1160,  1802,  2026,   838],\n",
       "        [  340,  2102,   640,    82,   326,   614,   531,   812,   352,   345],\n",
       "        [  198,  1729,  2116,  1462,  1029,   880,   890,   763,  1941,   662],\n",
       "        [  340,   531,    50,   471,   640,   606,   345,    16,   614,   502],\n",
       "        [  785,   290,   352,    16,  2398,   513,  1987,   860,   266,    18],\n",
       "        [   13,    12,   357, 15886,   720,   198,    28,    11,    14,   532],\n",
       "        [  198,    13,    12,   720,   357,  1303,    25, 15886,     7,    14],\n",
       "        [  198,    13,    12,    14,   357,   720,     7, 15886,  1303,  7375],\n",
       "        [  198,    13,    12,   357,   720,    14, 15886,     7,  4904,  1303],\n",
       "        [  198,    13,    12,    14,   357,   720, 15886,     7,    25,  1303],\n",
       "        [   13,   198,    12,   720,   357,    14, 15886,    11,    25,     7],\n",
       "        [   13,   198,    12,   357,   720,    14, 15886,    25,    11,     7],\n",
       "        [   13,   198,    12,    14,   357,   720,    11, 15886,    25,     7],\n",
       "        [   13,    12,   198,    14,   357,   720,    11, 15886,    25,   569],\n",
       "        [   13,    12,   198,   357,   720,    11,    25,    14, 15886,  1906],\n",
       "        [  352,   362,   531,   513,   838,   604,   642,   767,   718,  1367],\n",
       "        [  340,   251,   606,    82,   345,   640, 20766,   502,   683,  2624],\n",
       "        [  198,    79,   279,    47,   350,    91, 15886, 50256,    28,    25],\n",
       "        [  312,    85,  6371,    77,    79,   198,  2389,   279,  4686,  5420],\n",
       "        [  198,   785,    79,    64,  2398,  1671,   784,    13,   366,    65],\n",
       "        [  340,   345,   826,   326,   428,   466,   502,   606,   329,   783],\n",
       "        [ 3672,  3053,   198, 12888,  7508,   250,    13, 50256,     7,   986],\n",
       "        [  198, 50256,    13,    12,   250,   357,   366,     5,    14,     1],\n",
       "        [  198,   357,    12,    13, 50256,   250,     5,    14,    17,   366],\n",
       "        [  198,    13,   357,    12, 50256,    14,  7200,   250,   366,    91],\n",
       "        [  198,    13,   513,   357,    12, 50256,     5,   250,    14,   366],\n",
       "        [  198,    13,   357,    12, 50256,   250,    14,     5,   366, 15886],\n",
       "        [  198,   357,    12, 50256,    13,   250, 15886,  7200,   366,    14],\n",
       "        [  198,   357,    12, 50256,    13,   250,   642,   604,   513,   366],\n",
       "        [  198,   357,    12, 50256,    13,   250,   366,    14, 15886,  2022],\n",
       "        [  198,   250,   366, 50256,     1,   357,    13,   246,    12,   986],\n",
       "        [  198,    13,   357,    12, 50256,   250,   366,    14,    32, 15886],\n",
       "        [  198,   357,    13,    12, 50256,   604,   250,  3486,   366,   642],\n",
       "        [  198,   357,    12,    13, 50256,   250,    14,   366, 15886,    91],\n",
       "        [  198,   357,    12,    13, 50256,   250,     5,  8740,    14,   366],\n",
       "        [  198,   357,    12,    13, 50256,   250, 15886,    14,   366,    91],\n",
       "        [  198,    13,    12,   357,    14,   250, 50256,    17,   366,    56],\n",
       "        [  198,   357,    12,    13, 50256,   250,     5,   366,    14, 13793],\n",
       "        [  198,   357,    12, 50256,    13,   327,   337,    14,   402,    32],\n",
       "        [  198,   357,    13,    12, 50256,   250,    14,   366, 15886,     5],\n",
       "        [   13,   198,   357,    12, 50256,     6,   250,    14,   247,   366],\n",
       "        [  198,    12,   357,    13,     5, 50256,   250,    14,   366, 15886],\n",
       "        [  198,   357,    12,    13, 50256, 12460,  6579,   399,   250,   509],\n",
       "        [  198,   357,    12,   367,    13, 50256,    14,   250,   370,   366],\n",
       "        [  198,   357,    12,    13, 50256,   250,    14,   366,    91, 15886],\n",
       "        [  198,    12,   357,   327,  2538,    14,    49, 21664,   402, 15886],\n",
       "        [  198,    13,   357,    12, 50256,   250, 20571,  6489, 17931,  2767],\n",
       "        [  198,    12,   357,   412, 50256,   250,  2043,   327,    13,  3537],\n",
       "        [  198,   250, 50256,    91, 15886,   251,  1399,   986,   246,     0],\n",
       "        [25150,    13,    77,   198,    81, 30206, 44171, 13283,    62, 11209],\n",
       "        [ 6861,    82, 11713,  8134,   392,    64,   251, 21383,  2723,  6371],\n",
       "        [  198, 10563,    62,    13,   838,     8,    87,    12,   510,   362],\n",
       "        [   16,   198,    64,  1659, 26841,    17,  1169, 10563,    82,   259],\n",
       "        [  314,   836,   340,   198,   345,   632,   356,   326,  1422,   460],\n",
       "        [  357,    12,   198,   250,   960,     7,   366,    13,  4489,   514],\n",
       "        [   12,   357,   198,     7,    14,    13,   250,   366,   398,   275],\n",
       "        [   12,   357,   198,    14,     7,    13,   250,   319,   366,  1550],\n",
       "        [  247,    12,    17,   198,   357,    14,    18,    13,   250,   513],\n",
       "        [   13,   357,    12,   198,     7,  5899,    14, 16334, 19977,   500],\n",
       "        [   12,   198,   357,   250,    14,    13,   366,  4580,   523,  2270],\n",
       "        [   13,    12,   198,    14,   357,   250,  2537, 46832,   366,   337],\n",
       "        [   12,    14,   198,   357,    13,   250,   397,   283,   366,   732],\n",
       "        [  357,   198,    13,    12, 28931,  4715,  1669, 20493,  1162,     7],\n",
       "        [   14,    12,    13,   198,  8498,   430,  1215,  1526,   357,   440],\n",
       "        [  334,    12,    13,     7,   357,  2471,    14,   198,  1288,  8906],\n",
       "        [   12,   198,    14,   357,    13,   250,   425,  8105,   366,  1526],\n",
       "        [  247,    13,    12,    14,   198,   357, 40601,   250,  3652,  7245],\n",
       "        [   12,   357,   198,    13,    14,   246,   705,  1855,     6,   247],\n",
       "        [  800,   198,    12, 22354,    14, 21631, 10335,  1030,    13,   755],\n",
       "        [   12,   357,   198,    13,    14,   250, 17729,   366, 26250,   337],\n",
       "        [  311,  8678,    65,   314,   317, 19413,  2743,  4653,   412,    12],\n",
       "        [   12,   198,    13,   357,    14,  7956, 11033,   911,   450,   285],\n",
       "        [  247,    12,     7,    14,   246,   198,  7169,  8069,  6303,   357],\n",
       "        [  247,    12,   198,    14,   357,   250,    13,  8836,   366,  1378],\n",
       "        [ 1976, 22249,  6658,   267,  1188,  3059,  1765,   324,   300,  4118],\n",
       "        [   12,   357,   198,    13,    14,   645,    30, 23167,  1540,   250],\n",
       "        [   12,   198,    14,   357,   250,    13,   366,    65,   390,  2046],\n",
       "        [ 1674,  4558,    13,   352,   604,   362, 20934,    12,   502,   513],\n",
       "        [   12,  1304,  3311, 23527,  2344,  8615,   299,  1633,  4534, 12332],\n",
       "        [   12,  9940,  7364,  1360,  6069,   763,   710,  3248,  2501,  4849],\n",
       "        [   78,    94,    46,    70,    54,    38,    86,    22,    50,    26],\n",
       "        [  198,    13, 14726, 50256,     4,   405,     0,  3122,    16,    25],\n",
       "        [  198,  1058,   930,    12,    91,   407,  2314,     0,   286,    25],\n",
       "        [  198,    14,     9,  4907,    25,    13, 15886,     0, 50256,    91],\n",
       "        [  126,   140, 12466, 19567,  1587,  6184,   118,   165,   167,   447],\n",
       "        [ 6184,   147, 19567, 12466,   140,   165, 14360,   251, 17550,   252],\n",
       "        [26292, 19567, 17550,   148,   118,   129, 11976, 12466,   138,   119],\n",
       "        [11976, 43074, 32391, 12520,   126,  8582,  6184, 46695,   106, 24231],\n",
       "        [20724,   129, 41585, 19567,   242, 33768, 20015, 35705,   126, 17550],\n",
       "        [  126, 11976, 20724,   123, 27764,   167, 28225,   165,   147,   224]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3dab3cae-3bc6-466b-a0b3-8e09cdc469d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "word = tokenizer.decode([318])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d0feada1-b7bd-49db-956e-ccd7259f6f76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' is'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d2ffb842-23e6-4129-adc7-6c1d6da337ce",
   "metadata": {},
   "source": [
    "emb_input = rearrange(emb_input, \"(b s) k d -> b s k d\", s=s)\n",
    "e_router = self.experts_router[input_k] # (bsk, d)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95606b0c-3263-41f5-9132-58738d44c114",
   "metadata": {},
   "source": [
    "torch.cuda.synchronize()\n",
    "total_time_ms = 0\n",
    "last_time = time.time()\n",
    "if bincount_option:\n",
    "    y = x * (vocab_size + 1) + p\n",
    "    vocab_bin += torch.bincount(y.flatten(), minlength=size).reshape_as(vocab_bin)\n",
    "\n",
    "torch.cuda.synchronize()\n",
    "time_ms = 1000 * (time.time() - last_time)\n",
    "total_time_ms += time_ms\n",
    "tokens_per_ms = step_tokens / time_ms * 1000\n",
    "print(f\"step: {step} step_time: {time_ms:.1f}ms tpms: {tokens_per_ms:.1f} t/ms \")\n",
    "torch.cuda.synchronize()\n",
    "last_time = time.time()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7ecc546b-d2ca-4733-97b6-2916d3913736",
   "metadata": {},
   "source": [
    "vocab_emb = torch.randn(11, 65536, 16, device=device)\n",
    "vocab_bin = torch.rand(65536, device=device)\n",
    "torch.cuda.memory._record_memory_history()\n",
    "torch.cuda.empty_cache()\n",
    "if i == layer_num // 2:\n",
    "    torch.cuda.memory._dump_snapshot(f\"snapshot_layer{i}.pickle\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0614afb4-726e-4d86-810c-33fc9f7ebea1",
   "metadata": {},
   "source": [
    "1. 监测标准模式下的 indices & logits info\n",
    "2. 纯 main 模式 + 超大累积 batch size 并监测信息\n",
    "3. 标准模式 + router 模块极小学习率更新\n",
    "4. 以当前 block 作为 router\n",
    "5. 取消逐层选取专家\n",
    "6. 标准模式 + 训练中期固定 router"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd0bcf5c-7e08-423b-99c5-c84c17838baa",
   "metadata": {},
   "source": [
    "1. global attn\n",
    "2. two types of aux\n",
    "3. logits dynamics\n",
    "4. moe dynamics\n",
    "5. loss free aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "8325900b-e32a-486a-9df7-e2376a43505f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.x1 = nn.Linear(3, 4, bias=False)\n",
    "        self.x2 = nn.Linear(3, 4, bias=False)\n",
    "        self.x1.weight = self.x2.weight\n",
    "\n",
    "    def params_count(self):\n",
    "        x1_params = sum(x.numel() for x in self.x1.parameters())\n",
    "        x2_params = sum(x.numel() for x in self.x2.parameters())\n",
    "        params = sum(x.numel() for x in self.parameters())\n",
    "        return x1_params, x2_params, params"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4b626c5-8f2d-47d1-baf3-0ce992a4a0c3",
   "metadata": {},
   "source": [
    "def reweight(x, n, t, cond, w0, mask):\n",
    "    w_list = []\n",
    "    b_list = []\n",
    "    if w0 is None:\n",
    "        w0 = torch.ones_like(x)\n",
    "    w_list.append(w0)\n",
    "    # b0 = torch.bincount(x.flatten(), w0.flatten())\n",
    "    b0 = (F.one_hot(x, n).type_as(x) * w0.unsqueeze(-1)).flatten(0, -2).mean(0)\n",
    "    b0 = b0 / b0.sum() * n\n",
    "    b_list.append(b0)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1bda0cd-6ff9-4d9c-a379-ebcd1838b779",
   "metadata": {},
   "source": [
    "def params_count(self, config: Config):\n",
    "    total_params = sum(x.numel() for x in self.parameters())\n",
    "    ffn_h_dim = int(config.main_dim * config.ffn_factor)\n",
    "    et = config.expert_num_per_token\n",
    "    ffn_experts_train_params = (\n",
    "        3 * config.main_dim * ffn_h_dim * et * (config.layer_num - 1)\n",
    "    )\n",
    "    ffn_experts_infer_params = (\n",
    "        config.main_dim * config.vocab_size * et * (config.layer_num - 1)\n",
    "    )\n",
    "    ffn_experts_infer_a_params = (\n",
    "        config.main_dim * et * (config.layer_num - 1)\n",
    "    )\n",
    "    total_params = (\n",
    "        total_params - ffn_experts_train_params + ffn_experts_infer_params\n",
    "    )\n",
    "    total_a_params = total_params + ffn_experts_infer_a_params\n",
    "    params_result = {\n",
    "        \"total_params\": total_params,\n",
    "        \"total_a_params\": total_a_params,\n",
    "    }\n",
    "    return params_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e33e6f-94d6-4e10-87c7-2d25f30e6cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def params_count(self, config: Config):\n",
    "    total_params = sum(x.numel() for x in self.parameters())\n",
    "    et = config.expert_num_per_token\n",
    "    not_a_sub_expert_num = config.expert_num * config.sub_expert_num - 1\n",
    "    not_fa_sub_expert_num = (config.expert_num - et) * config.sub_expert_num\n",
    "\n",
    "    ffn_experts_coeff = (\n",
    "        config.main_dim\n",
    "        * (3 * config.sub_expert_dim + config.sub_expert_router)\n",
    "        * (config.layer_num - 1)\n",
    "    )\n",
    "    ffn_experts_not_a_params = ffn_experts_coeff * not_a_sub_expert_num\n",
    "    ffn_experts_not_fa_params = ffn_experts_coeff * not_fa_sub_expert_num\n",
    "\n",
    "    total_a_params = total_params - ffn_experts_not_a_params - config.main_dim * config.expert_num * (config.layer_num - 1)\n",
    "    total_fa_params = total_params - ffn_experts_not_fa_params\n",
    "    params_result = {\n",
    "        \"total_params\": total_params,\n",
    "        \"total_a_params\": total_a_params,\n",
    "        \"total_fa_params\": total_fa_params,\n",
    "    }\n",
    "    return params_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d96344-272f-4425-b994-cf99fba211bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_dense: bool\n",
    "p_ffn_factor: float\n",
    "f_dense: bool\n",
    "f_ffn_factor: float\n",
    "p_shared_expert: bool\n",
    "p_shared_expert_dim: int\n",
    "f_shared_expert: bool\n",
    "f_shared_expert_dim: int\n",
    "\n",
    "p_dim_s = config.p_shared_expert_dim\n",
    "f_dim_s = config.f_shared_expert_dim\n",
    "\n",
    "if config.p_dense:\n",
    "    self.p_ffn_h_dim = int(dim * config.p_ffn_factor)\n",
    "    self.p_dense_up = nn.Linear(dim, self.p_ffn_h_dim * 2, bias=False)\n",
    "    self.p_dense_down = nn.Linear(self.p_ffn_h_dim, dim, bias=False)\n",
    "else:\n",
    "    self.p_ffn_experts = nn.Parameter(torch.randn(3, ple, dim, p_dim))\n",
    "    if config.p_shared_expert:\n",
    "        self.p_ffn_up = nn.Linear(dim, p_dim_s * 2, bias=False)\n",
    "        self.p_ffn_down = nn.Linear(p_dim_s, dim, bias=False)\n",
    "\n",
    "if config.f_dense:\n",
    "    self.f_ffn_h_dim = int(dim * config.f_ffn_factor)\n",
    "    self.f_dense_up = nn.Linear(dim, self.f_ffn_h_dim * 2, bias=False)\n",
    "    self.f_dense_down = nn.Linear(self.f_ffn_h_dim, dim, bias=False)\n",
    "else:\n",
    "    self.f_ffn_experts = nn.Parameter(torch.randn(3, fle, dim, f_dim))\n",
    "    if config.f_shared_expert:\n",
    "        self.f_ffn_up = nn.Linear(dim, f_dim_s * 2, bias=False)\n",
    "        self.f_ffn_down = nn.Linear(f_dim_s, dim, bias=False)\n",
    "\n",
    "if config.p_dense:\n",
    "    px1, px2 = torch.split(self.p_dense_up(p_x_ffn), self.p_ffn_h_dim, -1)\n",
    "    px3 = F.silu(px1) * px2\n",
    "    py = self.p_dense_down(px3)\n",
    "else:\n",
    "    p_scores = p_values.sigmoid()\n",
    "    p_scores = p_scores / p_scores.sum(-1, keepdim=True)\n",
    "    p_indices = p_indices.flatten()\n",
    "    p_scores = p_scores.flatten().unsqueeze(-1) * config.p_routed_scaling_factor\n",
    "    py = grouped_gemm_func(\n",
    "        p_x_ffn, self.p_ffn_experts, p_indices, p_scores, config\n",
    "    )\n",
    "\n",
    "    if config.p_shared_expert:\n",
    "        px1, px2 = torch.split(\n",
    "            self.p_ffn_up(p_x_ffn), config.p_shared_expert_dim, -1\n",
    "        )\n",
    "        px3 = F.silu(px1) * px2\n",
    "        p_y_shared = self.p_ffn_down(px3)\n",
    "        py = py + p_y_shared\n",
    "\n",
    "    if config.f_dense:\n",
    "        fx1, fx2 = torch.split(self.f_dense_up(p_x_ffn), self.f_ffn_h_dim, -1)\n",
    "        fx3 = F.silu(fx1) * fx2\n",
    "        fy = self.f_dense_down(fx3)\n",
    "        py = py + fy\n",
    "\n",
    "if config.f_dense:\n",
    "    fx1, fx2 = torch.split(self.f_dense_up(f_x_ffn), self.f_ffn_h_dim, -1)\n",
    "    fx3 = F.silu(fx1) * fx2\n",
    "    fy = self.f_dense_down(fx3)\n",
    "else:\n",
    "    f_scores = f_values.sigmoid()\n",
    "    f_scores = f_scores / f_scores.sum(-1, keepdim=True)\n",
    "    f_indices = f_indices.flatten()\n",
    "    f_scores = f_scores.flatten().unsqueeze(-1) * config.f_routed_scaling_factor\n",
    "    fy = grouped_gemm_func(\n",
    "        f_x_ffn, self.f_ffn_experts, f_indices, f_scores, config\n",
    "    )\n",
    "\n",
    "    if config.f_shared_expert:\n",
    "        fx1, fx2 = torch.split(\n",
    "            self.f_ffn_up(f_x_ffn), config.f_shared_expert_dim, -1\n",
    "        )\n",
    "        fx3 = F.silu(fx1) * fx2\n",
    "        f_y_shared = self.f_ffn_down(fx3)\n",
    "        fy = fy + f_y_shared\n",
    "\n",
    "y = torch.cat([py, fy], dim=0) + x_ffn_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "6dd40742-69a4-449c-8a13-6ce108c2f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 64, (128, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "617f10c8-8f25-41d8-9998-0aec3dc5751d",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = torch.bincount(x.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "0a348545-73af-441c-91d0-af41ee93a870",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = b / b.sum() * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "1cedaad5-67ee-4f0d-affe-d213fb738204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.1, 1.2, 0.8, 0.4, 1.5, 1.0, 0.6, 1.2, 1.1, 0.8, 0.8, 1.0, 0.5, 1.2,\n",
       "        1.1, 0.8, 1.1, 1.4, 1.1, 1.0, 0.6, 1.0, 1.0, 1.2, 1.0, 0.8, 1.0, 1.2,\n",
       "        1.1, 1.6, 1.0, 1.0, 0.8, 0.6, 0.4, 1.6, 0.8, 1.1, 1.5, 1.4, 1.5, 1.6,\n",
       "        0.8, 1.1, 0.8, 0.5, 0.6, 1.2, 0.9, 1.0, 1.1, 1.5, 0.6, 1.5, 0.8, 0.9,\n",
       "        0.5, 0.6, 0.6, 1.1, 0.4, 1.0, 2.0, 0.9])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "c677822c-d897-4765-88b6-990b7fb63ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b = b[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "75d96678-74f4-450d-a81b-6ff9c7c7a69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 2 / (x_b.amax(-1, keepdim=True) + x_b.amax(-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "859c2321-a56c-47ed-b7a5-60d1a23f5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = w1.expand(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "60c30fd8-9a1e-401f-a288-6b6c5e6be87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = torch.bincount(x.flatten(), w1.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "5ab5aac5-6643-4626-9218-140334eb4795",
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = b1 / b1.sum() * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f0d2b2ac-da65-4b8f-b7d6-017cdba07eb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.2, 1.4, 0.8, 0.4, 1.4, 1.1, 0.5, 1.3, 1.3, 0.9, 0.7, 1.0, 0.5, 1.2,\n",
       "        1.2, 0.8, 1.3, 1.2, 1.3, 1.0, 0.6, 1.0, 1.0, 1.3, 1.1, 0.8, 1.1, 1.3,\n",
       "        1.1, 1.4, 1.0, 1.1, 0.7, 0.7, 0.4, 1.4, 0.9, 1.1, 1.4, 1.3, 1.4, 1.4,\n",
       "        0.8, 1.2, 0.8, 0.4, 0.6, 1.3, 1.0, 1.1, 1.1, 1.4, 0.7, 1.3, 0.8, 0.9,\n",
       "        0.5, 0.6, 0.6, 1.2, 0.3, 1.1, 1.4, 0.9])"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "3eaaebed-4dd5-4f8c-8e67-bf3b36741be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_b1 = b1[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "b3c747a9-c498-438e-8efb-cedbb9b89647",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = 2 / (x_b1.amin(-1, keepdim=True) + x_b1.amin(-1, keepdim=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "15072c41-74e8-4bb0-b519-b15d825e1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2 = w2.expand(-1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "52d305e6-96d0-412e-99f0-63c5b3155124",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = torch.bincount(x.flatten(), w1.flatten() * w2.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "6427bd35-f339-4607-86a3-8e56c74ad73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "b2 = b2 / b2.sum() * 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "cde34227-a4e1-4116-8a44-8bab89f7115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0, 1.1, 0.8, 0.7, 1.5, 0.8, 0.7, 1.2, 1.0, 0.9, 0.9, 1.0, 0.7, 1.2,\n",
       "        0.9, 1.1, 1.1, 1.3, 1.3, 0.8, 0.7, 0.9, 0.9, 1.1, 1.1, 0.8, 0.8, 1.3,\n",
       "        0.9, 1.4, 0.9, 1.0, 0.9, 0.7, 0.7, 1.6, 0.9, 1.1, 1.3, 1.3, 1.3, 1.4,\n",
       "        0.9, 1.1, 0.8, 0.7, 0.7, 1.2, 1.0, 0.9, 1.1, 1.4, 0.8, 1.3, 0.8, 0.8,\n",
       "        0.7, 0.8, 0.7, 1.1, 0.7, 1.0, 1.6, 1.0])"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37852c02-a1ce-41e3-9a8e-bf3e5e30163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def simulate_category_weights(n, m, a, b):\n",
    "\n",
    "    categories = torch.randint(0, n, (m,))\n",
    "    weights = torch.rand(m) * (b - a) + a\n",
    "    accumulated_weights = torch.zeros(n)\n",
    "    accumulated_weights.scatter_add_(0, categories, weights)\n",
    "    \n",
    "    return accumulated_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c9eed2e7-88ac-4bb4-b50f-cdedbd51e728",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=1, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "03926ae9-670a-44a1-ac3c-e77d50f6db72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9, 2.9, 3.3, 3.3, 4.6, 1.1, 4.1, 3.3, 3.6, 1.6, 3.6, 5.7, 8.3, 3.7,\n",
       "        4.9, 3.6, 4.2, 5.9, 5.2, 3.4, 2.1, 6.8, 3.6, 5.3, 3.2, 3.1, 1.9, 1.2,\n",
       "        4.4, 3.1, 3.0, 4.0, 4.6, 4.3, 5.0, 3.0, 4.8, 5.5, 2.9, 3.9, 2.2, 1.5,\n",
       "        4.6, 4.6, 1.0, 2.5, 5.1, 4.6, 3.5, 7.4, 3.5, 3.7, 4.1, 3.8, 1.8, 3.4,\n",
       "        6.6, 4.9, 7.8, 3.6, 4.1, 2.2, 3.6, 3.3])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_category_weights(64, 512, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "bbfda907-9141-4bb1-9cf9-5e7838e3b76d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    -0.0,      0.0,     -0.2,      0.3,      1.4,     -0.8,      0.5,\n",
       "             1.4,      0.0,     -0.2,      2.7,     -0.7,      0.0,      0.4,\n",
       "             0.0,      0.2,     -0.6,      0.0,     -0.5,     -0.8,     -0.5,\n",
       "             0.1,     -0.4,     -0.4,     -1.4,      0.0,     -0.3,      2.2,\n",
       "             0.6,      0.4,      0.0,      0.7,      0.4,      0.0,      0.4,\n",
       "             0.8,     -0.1,     -0.6,     -1.7,      0.2,      0.5,     -0.8,\n",
       "            -0.7,      0.0,      0.0,      0.3,      0.0,     -0.8,      0.0,\n",
       "             1.1,      0.1,     -0.2,     -0.4,     -0.9,      0.0,     -1.2,\n",
       "             0.0,      0.7,      0.0,     -0.5,      0.4,      0.0,     -0.6,\n",
       "            -1.7])"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_category_weights(64, 50, 0.1, 0.9) - simulate_category_weights(64, 50, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "12753e39-cce6-4616-9d87-969b15eaebe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 93.9, 113.0, 138.4,  84.9, 102.2, 107.9,  95.6,  95.4,  83.8, 104.5,\n",
       "        108.3,  94.8, 100.6, 113.3,  98.4,  77.6, 119.6,  94.4,  84.9,  97.8,\n",
       "         93.8,  98.3, 102.4,  97.4,  92.6,  98.5,  95.0, 112.5, 108.0, 111.6,\n",
       "        109.7, 103.9,  92.1,  87.0, 123.1, 103.0,  83.9, 104.6, 102.1,  91.8,\n",
       "         96.1, 100.0,  99.6, 125.8,  84.9, 106.3,  93.5, 103.9,  89.3,  90.0,\n",
       "         65.9, 101.7,  95.0, 101.1,  94.8,  93.7,  98.4, 109.6, 114.4, 121.7,\n",
       "        100.1, 101.7, 120.4, 103.1])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_category_weights(64, 5120, 0.1, 0.9) / 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "146f4344-06b9-40c3-8aff-b45bb91de89d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 90.8, 105.2, 101.8, 100.3,  98.2, 104.2, 105.7,  93.9, 111.1,  97.2,\n",
       "         95.8, 101.6,  99.3,  96.7,  93.4,  90.1,  99.4,  99.2, 105.9,  96.5,\n",
       "         97.6, 104.7, 116.1, 109.1,  98.6, 100.0,  99.9, 100.0, 106.2, 103.3,\n",
       "        104.1, 100.8, 102.5,  93.1, 108.8,  98.1,  93.8, 101.6,  95.9,  98.0,\n",
       "         93.0, 105.7,  79.7, 102.5,  98.7, 110.1,  86.9,  85.3,  92.5,  95.4,\n",
       "         87.6,  90.2, 105.3, 109.4, 113.1,  96.0,  99.8, 134.6,  92.9,  85.5,\n",
       "        117.5,  86.5,  95.3, 104.0])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_category_weights(64, 12800, 0.1, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "76950f5a-19ce-485e-9559-28d72f6a2883",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([104.9, 100.1, 101.5,  98.0,  99.8, 100.0,  99.1, 100.9, 100.8,  97.7,\n",
       "         98.7,  95.3, 104.5, 101.6,  99.0,  98.6, 101.7, 100.0, 100.0, 105.1,\n",
       "         98.5, 103.9, 100.5, 101.6, 100.2, 100.3, 100.1,  95.4, 100.8,  97.9,\n",
       "         93.7, 100.9,  99.0, 100.0,  98.1, 101.0,  98.3, 100.1, 103.3, 101.6,\n",
       "        101.0,  97.8,  98.3, 103.9,  96.5, 103.7, 104.4,  97.7,  95.9, 102.9,\n",
       "        102.9,  98.1,  95.8,  98.2, 102.0,  98.0, 100.0, 101.1,  97.9, 102.8,\n",
       "         98.9,  97.7, 107.0, 100.2, 106.3, 103.0,  99.6,  95.6,  95.5,  96.5,\n",
       "        102.2,  99.6, 100.9,  92.9,  98.0,  98.9, 100.5, 101.0, 102.5, 102.2,\n",
       "         98.4, 101.3, 100.1,  95.4,  98.3, 103.0, 100.8,  92.0,  98.2, 104.8,\n",
       "         99.1, 106.6,  99.1,  98.3, 101.0, 101.7, 103.9, 103.1,  99.0, 104.6,\n",
       "         99.8,  99.4, 102.1,  96.6, 100.3,  96.9, 101.1, 100.0, 102.3,  98.4,\n",
       "        100.0,  98.6, 100.2,  98.9,  98.8, 103.0, 100.6, 102.4, 106.5, 100.1,\n",
       "         98.5,  98.7,  97.9,  99.4,  98.8,  98.3,  98.7,  98.2, 102.4, 100.1,\n",
       "         97.9,  99.6, 101.2, 101.0,  99.6, 101.6, 100.9,  96.1,  99.2, 101.7,\n",
       "         97.4,  98.2,  97.2, 102.6, 101.4,  99.7, 100.3, 102.7,  97.1, 100.9,\n",
       "        100.5,  97.7,  99.3,  99.0,  99.0,  98.7,  96.4,  94.7, 101.1,  99.0,\n",
       "         97.7, 100.7,  97.1,  95.9,  97.6,  99.8, 102.7, 101.1, 100.9, 104.2,\n",
       "         96.0, 100.6, 100.4, 100.5,  98.2, 104.8,  96.0, 101.7,  97.4,  97.5,\n",
       "        107.6, 104.2,  98.1, 100.4, 101.5, 102.9, 102.2,  98.9,  92.9, 100.7,\n",
       "         96.6,  99.5,  99.9, 102.7, 100.8,  99.1, 100.1, 102.0,  97.3, 103.7,\n",
       "         99.1,  97.4,  99.5, 102.6,  99.0,  98.9,  99.2,  99.0,  99.9,  99.7,\n",
       "        101.2,  99.3,  97.1, 104.6, 103.3, 104.5,  95.7,  98.6, 101.9, 100.3,\n",
       "        105.1, 101.8,  98.1,  95.7,  99.4, 100.6, 102.4, 101.1, 102.8, 103.5,\n",
       "         97.3, 100.5, 101.9, 103.6,  97.8, 100.6,  98.4, 102.2, 101.5, 100.1,\n",
       "        100.8,  97.8, 101.8, 102.3,  96.7, 100.3,  98.9, 103.0, 103.0, 101.1,\n",
       "        102.0, 100.0, 105.4,  96.9,  96.8, 100.8, 100.4,  99.2,  93.9,  99.0,\n",
       "         96.6,  98.3,  97.9, 101.9,  99.2,  99.2, 106.2, 100.9, 102.7, 101.0,\n",
       "        101.0, 104.0, 102.3,  97.3, 100.1, 103.0,  96.9, 101.2, 103.8,  98.9,\n",
       "        101.9, 103.1, 102.2,  99.1, 102.3, 108.6,  97.3,  95.0,  97.0,  98.3,\n",
       "         94.4,  98.4, 102.6,  99.4,  98.6,  94.2,  97.5,  99.7, 105.0,  97.4,\n",
       "        100.1,  99.6,  94.2, 100.2,  98.1,  96.2, 100.0, 101.7,  98.6, 101.1,\n",
       "         99.8,  98.1, 101.3, 102.9,  99.9,  99.9, 104.5,  98.8,  98.7,  98.9,\n",
       "        105.5,  99.4,  95.6, 100.7,  98.1,  96.0, 101.2,  98.3, 102.5, 102.2,\n",
       "         99.8,  96.8,  99.7,  97.6,  96.2, 101.4,  98.3,  98.6,  99.5, 100.8,\n",
       "        100.7, 100.2, 100.0,  99.3,  98.1, 101.0,  95.5,  98.4,  99.2, 100.6,\n",
       "         97.3, 102.5,  96.8,  99.2,  98.2,  99.6, 100.7, 103.4,  98.8,  97.0,\n",
       "         95.5, 101.5,  97.6, 102.8, 101.5,  99.8, 100.9, 101.7,  99.7, 102.8,\n",
       "         97.1, 101.2, 101.1,  95.2,  99.5,  99.4,  98.8, 101.2,  99.1, 101.0,\n",
       "         97.1,  98.5,  99.6, 103.1, 100.4,  95.0, 100.5,  95.9, 102.9,  98.3,\n",
       "        104.4,  99.7, 100.7,  97.6, 104.0, 100.9, 103.4,  93.3, 102.5,  99.5])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_category_weights(400, 800000, 0.1, 0.9) / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "06b158f3-3040-4779-9c57-0851b15c927c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 98.4,  99.1,  99.0,  99.9, 100.4, 100.7,  98.9,  99.0, 100.8,  98.7,\n",
       "         99.9, 100.0,  99.7,  99.8,  99.8, 100.0, 100.9, 100.1, 100.4,  98.7,\n",
       "         99.7,  99.4, 101.0,  99.5, 100.8, 100.6,  99.3, 100.6, 100.7,  99.8,\n",
       "         99.9,  99.4,  99.2,  99.7, 101.8,  98.5, 100.4, 100.1, 100.1, 100.5,\n",
       "         99.1,  98.6,  99.7,  99.5, 100.0, 100.1,  99.7, 100.0, 100.4, 100.2,\n",
       "        100.6,  99.3, 100.4, 100.3,  99.4,  98.7, 100.1, 100.5,  99.5,  99.3,\n",
       "        100.1, 100.4, 100.0,  99.8, 100.8,  99.3, 100.0,  99.9, 101.6, 100.7,\n",
       "        100.8, 101.5,  98.9,  99.4, 100.3, 100.7,  99.3,  99.9, 100.6,  99.3,\n",
       "        100.4,  99.0, 100.6,  99.9, 100.5, 100.7, 100.6, 100.5, 101.6,  99.7,\n",
       "         99.2, 100.5,  98.5, 101.1, 101.1,  99.0,  99.7,  99.7, 100.8,  99.5,\n",
       "        100.6,  99.0, 100.8,  98.5, 100.5, 101.4, 100.3,  99.0,  99.2,  99.5,\n",
       "         99.8, 100.0,  99.5,  99.1, 100.3,  98.4, 100.3, 100.1,  98.8,  98.8,\n",
       "        100.0, 100.0, 101.8, 100.4,  99.5,  99.2,  99.8,  99.8,  99.7, 100.0,\n",
       "        101.1,  98.5, 100.1, 100.0,  99.5, 100.7,  99.5, 101.4,  99.8,  99.9,\n",
       "        100.8, 100.6, 100.0, 100.6,  99.1,  99.2, 100.1, 100.1,  98.3, 100.4,\n",
       "        100.7, 100.8,  99.0,  98.8, 100.2,  99.0,  99.6, 100.3,  98.7,  99.1,\n",
       "        100.0,  99.3,  98.4, 100.8,  99.3, 101.0, 101.1,  99.3,  99.4,  99.9,\n",
       "        100.5, 100.2, 100.7, 100.2, 100.0, 100.0, 100.5,  99.7,  99.3,  98.8,\n",
       "        100.2, 101.1,  99.9, 100.8, 101.0,  99.3, 100.3,  99.7,  99.7,  99.2,\n",
       "         99.7, 100.2,  98.1, 101.4,  99.3, 101.8, 101.0,  99.6, 100.6,  99.5,\n",
       "         99.6, 100.9, 100.0, 101.3,  99.1,  99.3, 100.3, 100.5,  99.0, 100.4,\n",
       "        101.2,  99.2,  99.2,  99.1,  99.0,  99.1, 102.4, 101.1, 101.7, 101.2,\n",
       "         99.0,  98.8, 100.6, 100.2,  99.9,  98.9, 100.4,  99.6,  99.1,  98.8,\n",
       "        100.9, 101.3,  99.2,  99.7,  99.1,  99.9,  98.4, 100.8,  98.7,  99.7,\n",
       "        101.4,  98.7,  98.9,  99.3,  99.6,  99.7, 100.5, 100.1,  99.6, 101.5,\n",
       "         99.5,  98.6, 100.2, 100.7, 100.8,  99.4,  99.1,  99.7,  99.8,  99.7,\n",
       "         99.4,  99.7, 100.8,  98.5,  99.7, 101.4, 100.8, 101.2, 101.1, 100.6,\n",
       "         98.0, 100.1,  99.4, 101.2, 100.1,  99.4,  99.7, 100.3, 100.2, 100.4,\n",
       "        100.5,  99.8,  99.7,  99.7, 101.5,  99.6, 100.2,  99.9, 100.7, 101.8,\n",
       "         99.3,  99.7, 100.2, 101.3, 102.6,  99.4, 100.6, 100.4, 100.7, 100.2,\n",
       "        100.8,  99.2,  99.4,  99.9,  99.4, 101.6,  99.2, 100.1, 100.9, 100.5,\n",
       "        100.2, 100.0, 100.5,  99.7,  99.4,  99.9, 100.9,  98.7, 100.2,  99.8,\n",
       "         99.0, 100.0, 100.1, 100.3,  99.7,  98.8,  99.9,  99.9, 101.2,  99.0,\n",
       "         99.3, 100.8,  99.4, 100.1,  98.6, 100.9, 100.4, 101.1, 100.6, 101.0,\n",
       "        100.4, 100.7, 101.1, 100.6,  99.8, 100.7,  99.9, 100.3,  99.6,  99.4,\n",
       "         99.6, 100.1,  99.8,  99.0, 100.2, 100.3, 100.3, 100.6, 100.7, 100.3,\n",
       "        101.0, 100.5,  99.4,  99.1, 101.4,  99.2,  99.8,  99.3,  99.7, 100.9,\n",
       "         98.8,  99.7, 100.2,  99.2, 101.2,  98.9,  99.9, 100.0,  99.2,  99.9,\n",
       "        100.4,  99.5,  98.2, 100.7,  99.4, 100.6,  99.0, 100.4, 100.1, 100.6,\n",
       "        100.0,  99.8,  99.9,  99.5, 100.6, 100.1,  98.5, 100.7,  98.7,  99.5])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_category_weights(400, 8000000, 0.1, 0.9) / 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
