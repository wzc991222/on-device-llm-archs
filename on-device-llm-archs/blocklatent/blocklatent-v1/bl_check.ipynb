{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f24f386-8181-4032-b398-c4b8633ec10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c0d7f6ef-f3b5-489c-bbeb-6469d97255b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc507d68-5b2e-4833-9826-b52c64a8ae5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = load_config(\"./config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3bff694e-8a42-48b7-a709-b51bcde97a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0847c2db-ce32-451f-897e-29e8083db231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'encoder_params': 9702400,\n",
       "  'main_params': 45235200,\n",
       "  'decoder_params': 13505024,\n",
       "  'ar_decoder_params': 9047040,\n",
       "  'model_params': 77489664,\n",
       "  'vocab_params': 32314880,\n",
       "  'total_params': 109804544},\n",
       " {'encoder_a_params': 24256000,\n",
       "  'main_a_params': 67852800,\n",
       "  'decoder_a_params': 60772608,\n",
       "  'ar_decoder_a_params': 36188160,\n",
       "  'model_a_params': 189069568,\n",
       "  'vocab_a_params': 45416448,\n",
       "  'total_a_params': 234486016})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params_count(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bc705543-2470-4ad7-bddf-d02f37d5ce3f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (attention): Attention(\n",
       "    (rotary_emb): RotaryEmb()\n",
       "  )\n",
       "  (vocab_emb): Embedding(50304, 512)\n",
       "  (encoder): Encoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-2): 3 x Layer(\n",
       "        (attn): Linear(in_features=512, out_features=1536, bias=False)\n",
       "        (attn_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (ffn_up): Linear(in_features=512, out_features=2560, bias=False)\n",
       "        (ffn_down): Linear(in_features=1280, out_features=512, bias=False)\n",
       "        (attn_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "        (ffn_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (latent_w1): Linear(in_features=512, out_features=768, bias=False)\n",
       "    (latent_w2): Linear(in_features=512, out_features=512, bias=False)\n",
       "  )\n",
       "  (main_model): MainModel(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x Layer(\n",
       "        (attn): Linear(in_features=512, out_features=1536, bias=False)\n",
       "        (attn_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (ffn_up): Linear(in_features=512, out_features=2560, bias=False)\n",
       "        (ffn_down): Linear(in_features=1280, out_features=512, bias=False)\n",
       "        (attn_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "        (ffn_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x Layer(\n",
       "        (attn): Linear(in_features=512, out_features=1536, bias=False)\n",
       "        (attn_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (ffn_up): Linear(in_features=512, out_features=2560, bias=False)\n",
       "        (ffn_down): Linear(in_features=1280, out_features=512, bias=False)\n",
       "        (attn_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "        (ffn_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (decoder_w1): Linear(in_features=512, out_features=1536, bias=False)\n",
       "    (decoder_w2): Linear(in_features=768, out_features=512, bias=False)\n",
       "    (decoder_output_linear): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (ar_decoder): ARDecoder(\n",
       "    (layers): ModuleList(\n",
       "      (0-3): 4 x Layer(\n",
       "        (attn): Linear(in_features=512, out_features=1536, bias=False)\n",
       "        (attn_o): Linear(in_features=512, out_features=512, bias=False)\n",
       "        (ffn_up): Linear(in_features=512, out_features=2560, bias=False)\n",
       "        (ffn_down): Linear(in_features=1280, out_features=512, bias=False)\n",
       "        (attn_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "        (ffn_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (y_latent_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "  (label_latent_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "  (final_norm): RMSNorm((512,), eps=1e-6, elementwise_affine=True)\n",
       "  (latent_head): Linear(in_features=512, out_features=12800, bias=False)\n",
       "  (lm_head): Linear(in_features=512, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4d728d12-dc2a-43e8-9d9e-16f951f02722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "223c4d37-40ad-402d-8e88-b623a60dd8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eot_idx = 1\n",
    "pad_idx = 0\n",
    "b = 8\n",
    "s = 64\n",
    "block_size = 8\n",
    "buffer = torch.randint(1, 16, (512,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6140c419-9d65-4e61-aadc-7a61daa893d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = torch.full((b, s + 1), pad_idx, dtype=torch.long)\n",
    "eot = torch.argwhere(buffer == eot_idx).squeeze(-1)\n",
    "eot_num = eot.shape[0]\n",
    "b_pos_left, b_pos_right, eot_pos = 0, 0, 0\n",
    "\n",
    "for row in range(b):\n",
    "    pos = 1\n",
    "    while pos <= s:\n",
    "        pad_num = random.randint(0, block_size - 1)\n",
    "        pos += pad_num\n",
    "        rest_len = s + 1 - pos\n",
    "\n",
    "        if eot_pos >= eot_num or (\n",
    "            eot_pos < eot_num and eot[eot_pos] - b_pos_left + 1 > rest_len\n",
    "        ):\n",
    "            b_pos_right = b_pos_left + rest_len\n",
    "            tokens[row, pos:] = buffer[b_pos_left:b_pos_right]\n",
    "            pos = s + 1\n",
    "            b_pos_left = b_pos_right\n",
    "        else:\n",
    "            b_pos_right = eot[eot_pos] + 1\n",
    "            s_len = b_pos_right - b_pos_left\n",
    "            tokens[row, pos : pos + s_len] = buffer[b_pos_left:b_pos_right]\n",
    "            end_pad = (block_size - (pos + s_len - 1) % block_size) % block_size\n",
    "            pos = pos + s_len + end_pad\n",
    "            b_pos_left = b_pos_right\n",
    "            eot_pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "46887a33-a0b8-48a5-9fc7-c7a94deaf8f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 10,  3,  4,  7, 15, 11,  1],\n",
       "        [ 0,  0,  0,  0,  0,  9,  4,  2],\n",
       "        [ 1,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0, 14,  8,  5,  7, 13],\n",
       "        [12, 14, 14, 10,  9, 10,  9, 12],\n",
       "        [ 9,  8,  6, 12, 15,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  5,  5,  2],\n",
       "        [ 4,  1,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  4,  2,  5,  4, 10, 15, 10],\n",
       "        [11,  8,  8, 10,  7,  2, 11, 12],\n",
       "        [ 9, 10,  5, 10,  2,  3, 11, 14],\n",
       "        [ 3, 11,  2, 10, 12,  7, 14,  1],\n",
       "        [12,  9,  3,  7,  6,  9, 13,  4],\n",
       "        [ 3, 14,  3,  5, 10, 11, 15, 13],\n",
       "        [ 6,  9, 12, 15,  7, 14,  4,  2],\n",
       "        [10,  9, 14, 14,  5,  9,  7,  1],\n",
       "        [ 0,  0,  0,  0,  0,  0,  4,  8],\n",
       "        [ 6,  3, 12,  8,  4,  7, 10, 13],\n",
       "        [14,  7,  7,  1,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  9,  2, 14, 14,  5],\n",
       "        [10,  4,  7, 15, 11,  8,  6,  8],\n",
       "        [ 7,  1,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0, 12,  7, 10,  5, 13, 13],\n",
       "        [ 3,  5,  7, 13,  8, 13,  7,  8],\n",
       "        [ 0,  0,  0,  0,  7,  3, 14,  9],\n",
       "        [ 5, 15,  7, 12,  9,  6, 10, 13],\n",
       "        [15, 11,  5,  4, 14,  7,  4,  8],\n",
       "        [11, 15,  5, 12,  7,  1,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0, 15,  4],\n",
       "        [14,  4,  2,  3, 11,  3,  4,  5],\n",
       "        [ 8,  9, 11,  1,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  7,  2,  9,  4],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  4],\n",
       "        [ 7, 13, 11, 13,  2,  4, 13,  6],\n",
       "        [14, 11,  5,  9, 13, 15,  3, 14],\n",
       "        [14, 15,  1,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  1,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0,  6, 11],\n",
       "        [11,  7,  4, 10,  1,  0,  0,  0],\n",
       "        [ 0,  0,  0,  1,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0, 12, 15, 15, 15,  9],\n",
       "        [ 8,  2, 13,  6,  2,  6, 10,  7],\n",
       "        [ 7, 13,  9, 10,  2,  7, 15,  9],\n",
       "        [10, 14,  4,  8,  7, 13, 14, 15],\n",
       "        [10, 15,  5,  9,  7,  8,  8,  4],\n",
       "        [ 2, 14, 11, 15, 13, 12,  1,  0],\n",
       "        [ 0,  0,  0,  4, 10,  8, 12,  6],\n",
       "        [ 3, 15, 11, 13,  2, 15, 12,  8],\n",
       "        [ 0,  0,  0,  0,  0,  0,  0,  1],\n",
       "        [ 0,  0,  0,  0,  6, 11, 13,  6],\n",
       "        [ 4,  3,  6, 10, 13, 11, 12, 12],\n",
       "        [ 6,  9,  5,  9, 13, 11,  9, 15],\n",
       "        [ 1,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0, 12, 13, 10,  2,  5,  4],\n",
       "        [13,  1,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  1,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0,  0, 13, 13],\n",
       "        [ 3,  3, 10,  7, 15,  7, 13, 13],\n",
       "        [ 2, 13, 10, 14, 14, 11, 13, 10],\n",
       "        [ 2, 15, 10,  9,  4, 11, 11,  7],\n",
       "        [ 7,  1,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  0,  0,  0,  0, 12,  8, 11],\n",
       "        [ 8,  6,  3,  8,  2, 11,  2,  8],\n",
       "        [ 9,  1,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[:, 1:].reshape(64, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "61f8f990-8e59-487c-ba24-ca616bcfd8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 2\n",
    "n = 2\n",
    "e = k + n\n",
    "include_previous_block = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "b8d71fc0-be98-4994-b88d-6842c225da17",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = torch.tensor([1, 1, 2]).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ed268271-0336-41cf-b89f-ddd51ba6c7f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 2]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "dd14812b-7ff0-40a2-ae61-1021ada3d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_mod_2(b, h, q_idx, kv_idx):\n",
    "    q_b_idx = q_idx // e\n",
    "    kv_b_idx = kv_idx // e\n",
    "    q_r_idx = q_idx % e\n",
    "    kv_r_idx = kv_idx % e\n",
    "    q_token = q_r_idx >= k\n",
    "    kv_token = kv_r_idx >= k\n",
    "    q_latent = q_r_idx < k\n",
    "    kv_latent = kv_r_idx < k\n",
    "    same_block = q_b_idx == kv_b_idx\n",
    "    causal_mask = q_idx >= kv_idx\n",
    "    intra_block_token_mask = q_token & same_block & causal_mask\n",
    "    inter_block_token_mask = False\n",
    "    if include_previous_block:\n",
    "        previous_block = q_b_idx == kv_b_idx + 1\n",
    "        doc_mask = doc[b, q_b_idx] == doc[b, kv_b_idx]\n",
    "        inter_block_token_mask = q_token & kv_token & previous_block & doc_mask\n",
    "    intra_block_latent_mask = q_latent & kv_latent & same_block\n",
    "    return (\n",
    "        intra_block_token_mask\n",
    "        | inter_block_token_mask\n",
    "        | intra_block_latent_mask\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "71f89adc-3b9a-485f-ba43-2a1e14d23429",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.full((12, 12), 2)\n",
    "for i in range(12):\n",
    "    for j in range(12):\n",
    "        result[i, j] = mask_mod_2(0, 0, i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "25674d0f-e342-4dfd-9c28-36345b9f25a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1]])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b997a60c-2be6-4867-9a8b-91301ac406eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
